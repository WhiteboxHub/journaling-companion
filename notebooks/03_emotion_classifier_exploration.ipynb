{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cell 2: Config & Constants\n",
    "DATA_PATH = Path(\"data/interim/journals.jsonl\")\n",
    "MODEL_PATH = Path(\"models/emotion_classifier\")\n",
    "LABELS = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\", \"curiosity\",\n",
    "    \"desire\", \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\",\n",
    "    \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n",
    "    \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data/interim/journals.jsonl\")\n",
    "MODEL_PATH = Path(\"models/emotion_classifier\")\n",
    "LABELS = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\", \"curiosity\",\n",
    "    \"desire\", \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\",\n",
    "    \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n",
    "    \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "# Cell 3: Load and clean dataset\n",
    "def load_entries(path):\n",
    "    entries = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                row = json.loads(line)\n",
    "                assert \"entry\" in row and \"emotions\" in row\n",
    "                entries.append(row)\n",
    "            except: continue\n",
    "    return entries\n",
    "\n",
    "entries = load_entries(DATA_PATH)\n",
    "print(f\"Loaded {len(entries)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_entries(path):\n",
    "    entries = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                row = json.loads(line)\n",
    "                assert \"entry\" in row and \"emotions\" in row\n",
    "                entries.append(row)\n",
    "            except: continue\n",
    "    return entries\n",
    "\n",
    "entries = load_entries(DATA_PATH)\n",
    "print(f\"Loaded {len(entries)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18634001",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emotions = [e for row in entries for e in row['emotions']]\n",
    "cnt = Counter(all_emotions)\n",
    "pd.Series(cnt).sort_values().plot(kind='barh', figsize=(10,8), title='Emotion Label Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(texts, model, tokenizer, threshold=0.5):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "    return (probs >= threshold).astype(int)\n",
    "\n",
    "sample_texts = [e['entry'] for e in entries[:100]]\n",
    "sample_true = [e['emotions'] for e in entries[:100]]\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=LABELS)\n",
    "true_bin = mlb.fit_transform(sample_true)\n",
    "pred_bin = predict(sample_texts, model, tokenizer)# Cell 7: Evaluation Metrics\n",
    "print(\"\\nClassification Report (Threshold = 0.5):\\n\")\n",
    "print(classification_report(true_bin, pred_bin, target_names=LABELS))\n",
    "\n",
    "# Optional: Average F1, Precision, Recall\n",
    "avg_f1 = f1_score(true_bin, pred_bin, average=\"micro\")\n",
    "avg_precision = precision_score(true_bin, pred_bin, average=\"micro\")\n",
    "avg_recall = recall_score(true_bin, pred_bin, average=\"micro\")\n",
    "\n",
    "print(f\"\\nAvg F1: {avg_f1:.4f} | Precision: {avg_precision:.4f} | Recall: {avg_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    text = sample_texts[i]\n",
    "    pred_labels = [LABELS[j] for j in range(len(LABELS)) if pred_bin[i][j] == 1]\n",
    "    true_labels = sample_true[i]\n",
    "    print(f\"\\nEntry {i+1}:\")\n",
    "    print(f\"Text: {text[:150]}...\")\n",
    "    print(f\"True: {true_labels}\\nPred: {pred_labels}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
